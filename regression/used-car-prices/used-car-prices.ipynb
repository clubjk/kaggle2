{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53c5b2bd-59ab-4c27-9ca0-9b5e3f1affc9",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/competitions/playground-series-s4e9/overview\n",
    "\n",
    "best score was using Linear Regression model w default hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa0f916-1925-47c8-92b6-1deb35b0ea09",
   "metadata": {},
   "source": [
    "prompt:\n",
    "The goal of this competition is to predict the price of used cars based on various attributes.\n",
    "Submissions are scored on the root mean squared error. \n",
    "\n",
    "The submission.csv file should be formatted like this:\n",
    "id,price\n",
    "188533,43878.016\n",
    "188534,43878.016\n",
    "188535,43878.016\n",
    "etc.\n",
    "\n",
    "the data for this challenge is:\n",
    "/home/john/ai/kaggle2/data/regression/used-car-prices/train.csv\n",
    "the training dataset; price is the continuous target\n",
    "\n",
    "/home/john/ai/kaggle2/data/regression/used-car-prices/test.csv\n",
    "the test dataset; your objective is to predict the value of price for each row\n",
    "\n",
    "/home/john/ai/kaggle2/data/regression/used-car-prices/sample_submission.csv\n",
    "a sample submission file in the correct format.\n",
    "\n",
    "I would like to prepare the data to train four popular models.\n",
    "Some of the features are catgorial so they will need to be encoded.\n",
    "\n",
    "Let's start with the data preparation in one block\n",
    "\n",
    "Then we will train the models.\n",
    "\n",
    "Important: after each of the four models are trained, pick the one with the best root mean squared error and create a submission.csv as per the prescribed format.\n",
    "\n",
    "I would also like some kind of way to monitor progress of the training in progress.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c91cedd-9590-4ad6-9fb9-d18eed56c5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Load datasets\n",
    "train_df = pd.read_csv('/home/john/ai/kaggle2/data/regression/used-car-prices/train.csv')\n",
    "test_df = pd.read_csv('/home/john/ai/kaggle2/data/regression/used-car-prices/test.csv')\n",
    "sample_submission = pd.read_csv('/home/john/ai/kaggle2/data/regression/used-car-prices/sample_submission.csv')\n",
    "\n",
    "# Separate features and target variable from the training set\n",
    "X = train_df.drop(columns=['price'])\n",
    "y = train_df['price']\n",
    "\n",
    "# Split training data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "numerical_features = X.select_dtypes(exclude=['object']).columns\n",
    "\n",
    "# Preprocessing pipeline for numerical and categorical data\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),  # Fill missing values with median\n",
    "    ('scaler', StandardScaler())  # Scale numerical features\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Fill missing categorical values\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))  # One-hot encode categorical features\n",
    "])\n",
    "\n",
    "# Combine the transformations into a preprocessor\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numerical_transformer, numerical_features),\n",
    "    ('cat', categorical_transformer, categorical_features)\n",
    "])\n",
    "\n",
    "# Return the preprocessed training and validation data for model training\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "X_train_preprocessed = pipeline.fit_transform(X_train)\n",
    "X_val_preprocessed = pipeline.transform(X_val)\n",
    "X_test_preprocessed = pipeline.transform(test_df)\n",
    "\n",
    "# Monitor progress using callbacks (for tree-based models, you can track iterations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a37887df-718f-4046-a903-4e6557f8a496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Linear Regression...\n",
      "Linear Regression RMSE: 69312.44919246348\n",
      "Time taken for Linear Regression: 12.66 seconds\n",
      "Training Random Forest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [1:14:49<00:00, 449.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest RMSE: 75637.44195670752\n",
      "Time taken for Random Forest: 4492.63 seconds\n",
      "Training Gradient Boosting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:22<00:00,  2.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting RMSE: 69688.3041183227\n",
      "Time taken for Gradient Boosting: 22.75 seconds\n",
      "Training XGBoost...\n",
      "[0]\tvalidation_0-rmse:72263.82524\n",
      "[1]\tvalidation_0-rmse:70963.23408\n",
      "[2]\tvalidation_0-rmse:70375.14722\n",
      "[3]\tvalidation_0-rmse:69993.30649\n",
      "[4]\tvalidation_0-rmse:69811.84043\n",
      "[5]\tvalidation_0-rmse:69823.25140\n",
      "[6]\tvalidation_0-rmse:69794.29815\n",
      "[7]\tvalidation_0-rmse:69887.63693\n",
      "[8]\tvalidation_0-rmse:69831.57490\n",
      "[9]\tvalidation_0-rmse:69791.82599\n",
      "[10]\tvalidation_0-rmse:69787.73642\n",
      "[11]\tvalidation_0-rmse:69762.64038\n",
      "[12]\tvalidation_0-rmse:69772.29454\n",
      "[13]\tvalidation_0-rmse:69814.86923\n",
      "[14]\tvalidation_0-rmse:69803.35074\n",
      "[15]\tvalidation_0-rmse:69809.04029\n",
      "[16]\tvalidation_0-rmse:69776.45313\n",
      "[17]\tvalidation_0-rmse:69769.15829\n",
      "[18]\tvalidation_0-rmse:69842.79340\n",
      "[19]\tvalidation_0-rmse:69933.25848\n",
      "[20]\tvalidation_0-rmse:69935.46454\n",
      "[21]\tvalidation_0-rmse:69953.39074\n",
      "[22]\tvalidation_0-rmse:69949.06340\n",
      "[23]\tvalidation_0-rmse:69975.16626\n",
      "[24]\tvalidation_0-rmse:69961.36185\n",
      "[25]\tvalidation_0-rmse:69957.69574\n",
      "[26]\tvalidation_0-rmse:70064.97386\n",
      "[27]\tvalidation_0-rmse:70085.91248\n",
      "[28]\tvalidation_0-rmse:70107.00807\n",
      "[29]\tvalidation_0-rmse:70159.43185\n",
      "[30]\tvalidation_0-rmse:70153.72913\n",
      "[31]\tvalidation_0-rmse:70146.19409\n",
      "[32]\tvalidation_0-rmse:70176.45575\n",
      "[33]\tvalidation_0-rmse:70182.76724\n",
      "[34]\tvalidation_0-rmse:70191.43918\n",
      "[35]\tvalidation_0-rmse:70271.27938\n",
      "[36]\tvalidation_0-rmse:70291.98796\n",
      "[37]\tvalidation_0-rmse:70278.72300\n",
      "[38]\tvalidation_0-rmse:70342.43300\n",
      "[39]\tvalidation_0-rmse:70454.22961\n",
      "[40]\tvalidation_0-rmse:70490.76964\n",
      "[41]\tvalidation_0-rmse:70528.26164\n",
      "[42]\tvalidation_0-rmse:70540.72189\n",
      "[43]\tvalidation_0-rmse:70544.41706\n",
      "[44]\tvalidation_0-rmse:70566.20499\n",
      "[45]\tvalidation_0-rmse:70596.89482\n",
      "[46]\tvalidation_0-rmse:70633.86205\n",
      "[47]\tvalidation_0-rmse:70636.33857\n",
      "[48]\tvalidation_0-rmse:70632.30451\n",
      "[49]\tvalidation_0-rmse:70805.24090\n",
      "[50]\tvalidation_0-rmse:71040.91348\n",
      "[51]\tvalidation_0-rmse:71091.45771\n",
      "[52]\tvalidation_0-rmse:71088.62947\n",
      "[53]\tvalidation_0-rmse:71109.71063\n",
      "[54]\tvalidation_0-rmse:71123.42888\n",
      "[55]\tvalidation_0-rmse:71139.69713\n",
      "[56]\tvalidation_0-rmse:71148.62034\n",
      "[57]\tvalidation_0-rmse:71154.72210\n",
      "[58]\tvalidation_0-rmse:71158.93471\n",
      "[59]\tvalidation_0-rmse:71204.83118\n",
      "[60]\tvalidation_0-rmse:71196.97899\n",
      "[61]\tvalidation_0-rmse:71203.22120\n",
      "[62]\tvalidation_0-rmse:71233.47273\n",
      "[63]\tvalidation_0-rmse:71311.86075\n",
      "[64]\tvalidation_0-rmse:71324.21527\n",
      "[65]\tvalidation_0-rmse:71409.72807\n",
      "[66]\tvalidation_0-rmse:71415.89059\n",
      "[67]\tvalidation_0-rmse:71433.46412\n",
      "[68]\tvalidation_0-rmse:71518.80523\n",
      "[69]\tvalidation_0-rmse:71534.63048\n",
      "[70]\tvalidation_0-rmse:71523.77243\n",
      "[71]\tvalidation_0-rmse:71554.92353\n",
      "[72]\tvalidation_0-rmse:71559.68769\n",
      "[73]\tvalidation_0-rmse:71570.50859\n",
      "[74]\tvalidation_0-rmse:71569.41280\n",
      "[75]\tvalidation_0-rmse:71581.30857\n",
      "[76]\tvalidation_0-rmse:71563.29844\n",
      "[77]\tvalidation_0-rmse:71646.03366\n",
      "[78]\tvalidation_0-rmse:71646.83537\n",
      "[79]\tvalidation_0-rmse:71649.55110\n",
      "[80]\tvalidation_0-rmse:71698.29040\n",
      "[81]\tvalidation_0-rmse:71888.00653\n",
      "[82]\tvalidation_0-rmse:71936.35525\n",
      "[83]\tvalidation_0-rmse:72074.52273\n",
      "[84]\tvalidation_0-rmse:72142.98578\n",
      "[85]\tvalidation_0-rmse:72152.79859\n",
      "[86]\tvalidation_0-rmse:72159.28715\n",
      "[87]\tvalidation_0-rmse:72224.76444\n",
      "[88]\tvalidation_0-rmse:72222.19824\n",
      "[89]\tvalidation_0-rmse:72227.87888\n",
      "[90]\tvalidation_0-rmse:72225.83219\n",
      "[91]\tvalidation_0-rmse:72416.25033\n",
      "[92]\tvalidation_0-rmse:72623.13662\n",
      "[93]\tvalidation_0-rmse:72635.05146\n",
      "[94]\tvalidation_0-rmse:72789.28360\n",
      "[95]\tvalidation_0-rmse:72791.71499\n",
      "[96]\tvalidation_0-rmse:72791.55584\n",
      "[97]\tvalidation_0-rmse:72791.12106\n",
      "[98]\tvalidation_0-rmse:72796.81281\n",
      "[99]\tvalidation_0-rmse:73184.16325\n",
      "XGBoost RMSE: 73184.16315780315\n",
      "Time taken for XGBoost: 48.87 seconds\n",
      "Best model: Linear Regression with RMSE: 69312.44919246348\n",
      "Submission file created.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries for progress tracking\n",
    "import time\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "import xgboost as xgb\n",
    "from tqdm import tqdm  # to add progress bars where necessary\n",
    "\n",
    "# Define the models with initial hyperparameters\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
    "    'XGBoost': xgb.XGBRegressor(n_estimators=100, random_state=42, verbosity=1)  # Verbosity for XGBoost\n",
    "}\n",
    "\n",
    "# Dictionary to store RMSE for each model\n",
    "rmse_scores = {}\n",
    "\n",
    "# Function to calculate RMSE\n",
    "def calculate_rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# Train each model and monitor progress\n",
    "for model_name, model in models.items():\n",
    "    print(f'Training {model_name}...')\n",
    "    start_time = time.time()\n",
    "\n",
    "    if model_name == 'Linear Regression':\n",
    "        # No progress tracking available, so we only measure time and RMSE\n",
    "        model.fit(X_train_preprocessed, y_train)\n",
    "    \n",
    "    elif model_name == 'Random Forest':\n",
    "        # Monitor progress of Random Forest training\n",
    "        model = RandomForestRegressor(n_estimators=100, warm_start=True, random_state=42)\n",
    "        for i in tqdm(range(1, 101, 10)):  # Adding trees in increments of 10 to monitor progress\n",
    "            model.set_params(n_estimators=i)\n",
    "            model.fit(X_train_preprocessed, y_train)\n",
    "    \n",
    "    elif model_name == 'Gradient Boosting':\n",
    "        # Monitor progress of Gradient Boosting training\n",
    "        model = GradientBoostingRegressor(n_estimators=100, warm_start=True, random_state=42)\n",
    "        for i in tqdm(range(1, 101, 10)):  # Incrementally add 10 trees\n",
    "            model.set_params(n_estimators=i)\n",
    "            model.fit(X_train_preprocessed, y_train)\n",
    "    \n",
    "    elif model_name == 'XGBoost':\n",
    "        # XGBoost has built-in verbosity for monitoring\n",
    "        model.fit(X_train_preprocessed, y_train, eval_set=[(X_val_preprocessed, y_val)], verbose=True)\n",
    "\n",
    "    # Predict on validation set\n",
    "    y_val_pred = model.predict(X_val_preprocessed)\n",
    "    \n",
    "    # Calculate RMSE\n",
    "    rmse = calculate_rmse(y_val, y_val_pred)\n",
    "    rmse_scores[model_name] = rmse\n",
    "    print(f'{model_name} RMSE: {rmse}')\n",
    "    \n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f'Time taken for {model_name}: {elapsed_time:.2f} seconds')\n",
    "\n",
    "# Select the model with the lowest RMSE\n",
    "best_model_name = min(rmse_scores, key=rmse_scores.get)\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "print(f'Best model: {best_model_name} with RMSE: {rmse_scores[best_model_name]}')\n",
    "\n",
    "# Train the best model on the entire training data\n",
    "best_model.fit(pipeline.transform(X), y)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = best_model.predict(X_test_preprocessed)\n",
    "\n",
    "# Prepare the submission file\n",
    "submission = pd.DataFrame({'id': test_df['id'], 'price': y_test_pred})\n",
    "submission.to_csv('/home/john/ai/kaggle2/data/regression/used-car-prices/submission.csv', index=False)\n",
    "print('Submission file created.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b7e320-ce6e-4a21-b418-9df6b502b992",
   "metadata": {},
   "source": [
    "Best model: Linear Regression with RMSE: 69312.44919246348\n",
    "Submission file created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe9ba87-3812-4327-bb66-a990af416f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "# Function to calculate RMSE\n",
    "def calculate_rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# Define the hyperparameters for Linear Regression\n",
    "fit_intercept_options = [True, False]\n",
    "positive_options = [True, False]\n",
    "\n",
    "# Store the best combination of hyperparameters and the corresponding RMSE\n",
    "best_rmse = float(\"inf\")\n",
    "best_hyperparameters = {}\n",
    "\n",
    "# Get all combinations of hyperparameters using itertools.product\n",
    "hyperparameter_combinations = list(itertools.product(fit_intercept_options, positive_options))\n",
    "\n",
    "# Loop through each combination of hyperparameters\n",
    "for i, (fit_intercept, positive) in enumerate(hyperparameter_combinations):\n",
    "    print(f\"Training permutation {i+1}/{len(hyperparameter_combinations)}:\")\n",
    "    print(f\"  - fit_intercept: {fit_intercept}\")\n",
    "    print(f\"  - positive: {positive}\")\n",
    "\n",
    "    # Create the model with the current set of hyperparameters\n",
    "    model = LinearRegression(fit_intercept=fit_intercept, positive=positive)\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train_preprocessed, y_train)\n",
    "    \n",
    "    # Predict on the validation set\n",
    "    y_val_pred = model.predict(X_val_preprocessed)\n",
    "    \n",
    "    # Calculate RMSE\n",
    "    rmse = calculate_rmse(y_val, y_val_pred)\n",
    "    print(f\"  - RMSE: {rmse}\\n\")\n",
    "    \n",
    "    # Check if this RMSE is the best so far\n",
    "    if rmse < best_rmse:\n",
    "        best_rmse = rmse\n",
    "        best_hyperparameters = {'fit_intercept': fit_intercept, 'positive': positive}\n",
    "\n",
    "# Output the best hyperparameter combination and RMSE\n",
    "print(f\"Best hyperparameters:\")\n",
    "print(f\"  - fit_intercept: {best_hyperparameters['fit_intercept']}\")\n",
    "print(f\"  - positive: {best_hyperparameters['positive']}\")\n",
    "print(f\"Best RMSE: {best_rmse}\")\n",
    "\n",
    "# Train the best model on the full training data\n",
    "best_model = LinearRegression(**best_hyperparameters)\n",
    "best_model.fit(pipeline.transform(X), y)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = best_model.predict(X_test_preprocessed)\n",
    "\n",
    "# Prepare the submission file\n",
    "submission = pd.DataFrame({'id': test_df['id'], 'price': y_test_pred})\n",
    "submission.to_csv('/home/john/ai/kaggle2/data/regression/used-car-prices/submission.csv', index=False)\n",
    "print('Submission file created.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d5ac29-035e-4f1b-bc55-4afd4db3bd7c",
   "metadata": {},
   "source": [
    "prompt:\n",
    "I would find out which permutation of all possible hyperparameters of the Linear Regression model results the lowest RMSE. Please write the code for this.  after each round of training give me the permutation and RMSE. After all the permutations have been tried, choose the combination of hyperparameters that has the lowest RMSE and create the submission.csv.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ee6c258-faba-499b-9fd3-1093216e4b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training permutation 1/4:\n",
      "  - fit_intercept: True\n",
      "  - positive: True\n",
      "  - RMSE: 69636.20854076598\n",
      "\n",
      "Training permutation 2/4:\n",
      "  - fit_intercept: True\n",
      "  - positive: False\n",
      "  - RMSE: 1813767573304.7864\n",
      "\n",
      "Training permutation 3/4:\n",
      "  - fit_intercept: False\n",
      "  - positive: True\n",
      "  - RMSE: 69490.48201420742\n",
      "\n",
      "Training permutation 4/4:\n",
      "  - fit_intercept: False\n",
      "  - positive: False\n",
      "  - RMSE: 197604789544355.44\n",
      "\n",
      "Best hyperparameters:\n",
      "  - fit_intercept: False\n",
      "  - positive: True\n",
      "Best RMSE: 69490.48201420742\n",
      "Submission file created.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "# Load datasets\n",
    "train_df = pd.read_csv('/home/john/ai/kaggle2/data/regression/used-car-prices/train.csv')\n",
    "test_df = pd.read_csv('/home/john/ai/kaggle2/data/regression/used-car-prices/test.csv')\n",
    "\n",
    "# Separate features and target variable from the training set\n",
    "X = train_df.drop(columns=['price'])\n",
    "y = train_df['price']\n",
    "\n",
    "# Split training data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "numerical_features = X.select_dtypes(exclude=['object']).columns\n",
    "\n",
    "# Preprocessing pipeline for numerical and categorical data\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))  # Corrected sparse argument\n",
    "])\n",
    "\n",
    "# Combine the transformations into a preprocessor\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numerical_transformer, numerical_features),\n",
    "    ('cat', categorical_transformer, categorical_features)\n",
    "])\n",
    "\n",
    "# Fit the preprocessor on the training data and transform both training and validation sets\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "X_val_preprocessed = preprocessor.transform(X_val)\n",
    "X_test_preprocessed = preprocessor.transform(test_df)\n",
    "\n",
    "# Function to calculate RMSE\n",
    "def calculate_rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# Define the hyperparameters for Linear Regression\n",
    "fit_intercept_options = [True, False]\n",
    "positive_options = [True, False]\n",
    "\n",
    "# Store the best combination of hyperparameters and the corresponding RMSE\n",
    "best_rmse = float(\"inf\")\n",
    "best_hyperparameters = {}\n",
    "\n",
    "# Get all combinations of hyperparameters using itertools.product\n",
    "hyperparameter_combinations = list(itertools.product(fit_intercept_options, positive_options))\n",
    "\n",
    "# Loop through each combination of hyperparameters\n",
    "for i, (fit_intercept, positive) in enumerate(hyperparameter_combinations):\n",
    "    print(f\"Training permutation {i+1}/{len(hyperparameter_combinations)}:\")\n",
    "    print(f\"  - fit_intercept: {fit_intercept}\")\n",
    "    print(f\"  - positive: {positive}\")\n",
    "\n",
    "    # Create the model with the current set of hyperparameters\n",
    "    model = LinearRegression(fit_intercept=fit_intercept, positive=positive)\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train_preprocessed, y_train)\n",
    "    \n",
    "    # Predict on the validation set\n",
    "    y_val_pred = model.predict(X_val_preprocessed)\n",
    "    \n",
    "    # Calculate RMSE\n",
    "    rmse = calculate_rmse(y_val, y_val_pred)\n",
    "    print(f\"  - RMSE: {rmse}\\n\")\n",
    "    \n",
    "    # Check if this RMSE is the best so far\n",
    "    if rmse < best_rmse:\n",
    "        best_rmse = rmse\n",
    "        best_hyperparameters = {'fit_intercept': fit_intercept, 'positive': positive}\n",
    "\n",
    "# Output the best hyperparameter combination and RMSE\n",
    "print(f\"Best hyperparameters:\")\n",
    "print(f\"  - fit_intercept: {best_hyperparameters['fit_intercept']}\")\n",
    "print(f\"  - positive: {best_hyperparameters['positive']}\")\n",
    "print(f\"Best RMSE: {best_rmse}\")\n",
    "\n",
    "# Train the best model on the full training data\n",
    "best_model = LinearRegression(**best_hyperparameters)\n",
    "best_model.fit(preprocessor.transform(X), y)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = best_model.predict(X_test_preprocessed)\n",
    "\n",
    "# Prepare the submission file\n",
    "submission = pd.DataFrame({'id': test_df['id'], 'price': y_test_pred})\n",
    "submission.to_csv('/home/john/ai/kaggle2/data/regression/used-car-prices/submission.csv', index=False)\n",
    "print('Submission file created.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6d7a30-3843-4a27-812c-bce00b89f1d1",
   "metadata": {},
   "source": [
    "best score was using Linear Regression model w default hyperparameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (new_ml_env)",
   "language": "python",
   "name": "new_ml_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
